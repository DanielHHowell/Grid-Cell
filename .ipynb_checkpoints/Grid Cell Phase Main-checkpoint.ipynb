{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Cell Phase Coding \n",
    "\n",
    "\"Phases are in radians, coordinates are in [m] and time base is [ms]. The first data point in XYspkT corresponds with the first spike, which also corresponds with the first phase value\"\n",
    "\n",
    "After changing parameters in the second cell, from the top menu click 'Cell' -> 'Run All' then scroll through\n",
    "\n",
    "(TODO: add firing map, low variance phase map?)\n",
    "\n",
    "(note whether coordinates in numpy [-y,x] or Cartesian [x,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "from astropy.stats import circcorrcoef\n",
    "import astropy.units as u\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(suppress=True)\n",
    "%config InLineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'datasets/1/'\n",
    "\n",
    "#Spatial or temporal analysis\n",
    "analysis_type = 'temporal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XYspkT\n",
    "\n",
    "XYspkT contains the X,Y coordinates of spikes. Spikes from all 30 neurons are combined in a single spike train. The X and Y columns represent the avatar's X-Y coordinate in [m] relative to the environment at the moment of the spike. \n",
    "\n",
    "XYspkT is float values, can be converted to integer with np.round(scaled_XY) as the coarse spatial analysis from the adjacency matrix only results in integer movement predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XYspkT = np.loadtxt(dir+'XYspkT.csv',delimiter=',')\n",
    "\n",
    "#Aligns positions to [0,0] in the bottom-left corner\n",
    "XYspkT[:,1] -= XYspkT[:,1].min()\n",
    "XYspkT[:,0] -= XYspkT[:,0].min()\n",
    "scaled_XY = XYspkT/2\n",
    "\n",
    "plt.plot(scaled_XY[:,0],scaled_XY[:,1],'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spkT\n",
    "\n",
    "spkT contains the times of the spikes in ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spkT = np.loadtxt(dir+'spkT.csv',delimiter=',')\n",
    "print(spkT)\n",
    "spkT.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase\n",
    "\n",
    "Phase is the corresponding (gamma) phase of the spikes - what phase the gamma oscillation was at them moment of spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = np.loadtxt(dir+'Phase.csv',delimiter=',')\n",
    "scaled_phase = phase-3.14\n",
    "\n",
    "phase_degrees = np.degrees(phase)\n",
    "sorted_phase = np.sort(phase_degrees)\n",
    "\n",
    "\n",
    "#Radial histogram of phase distribution\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8], polar=True)\n",
    "theta = np.radians(np.arange(0,366,6))\n",
    "\n",
    "inds = [np.where(sorted_phase<i)[0][-1] for i in np.arange(6,366,6)] #vectorize operation?\n",
    "b = np.split(sorted_phase,inds)\n",
    "radii = np.array([i.size/3.2 for i in b])\n",
    "\n",
    "width = np.radians(360/60)\n",
    "bars = ax.bar(theta, radii, width=width, bottom=0.0)\n",
    "for theta, bar in zip(theta, bars):\n",
    "    bar.set_facecolor(plt.cm.hsv(theta/6.28))\n",
    "    bar.set_alpha(0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MeanPhaseMap\n",
    "\n",
    "MeanPhaseMap the map of gamma phases. This is a 40x43 matrix that represents the 80x86 m land of the desert, the area covered by the avatar's navigation. The lot of NaN data correspond with areas never visited. A given value at the n-th row and m-th column represents the average phase of spikes (all spikes) within that area during the entire 5 min navigation. \n",
    "\n",
    "TODO:\n",
    "\n",
    "-(time based meanphasemap of first half, traj from second)\n",
    "\n",
    "-average internode distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_phase_map(arr,bin_size):\n",
    "    mpm_dict = {}\n",
    "    for ybin in range(0,int(arr[:,1].max()+1),bin_size):\n",
    "        mpm_dict[ybin] = {}\n",
    "        for xbin in range(0,int(arr[:,0].max()+1),bin_size):\n",
    "            phases = []\n",
    "            mpm_dict[ybin][xbin] = []\n",
    "            for spike in arr:\n",
    "                if (xbin <= spike[0] <= xbin+bin_size) and (ybin <= spike[1] <= ybin+bin_size):\n",
    "                    phases.append(spike[2])      \n",
    "            mpm_dict[ybin][xbin] = np.nanmean(np.asarray(phases))\n",
    "    return mpm_dict\n",
    "\n",
    "mpm_arr = np.column_stack((XYspkT,scaled_phase))\n",
    "mpm_dict = mean_phase_map(mpm_arr,2)\n",
    "\n",
    "#Rotate the dataframe 90 CCW\n",
    "mpm = pd.DataFrame.from_dict(mpm_dict).T\n",
    "phase_df = mpm.reindex(index=mpm.index[::-1])\n",
    "\n",
    "arena_size = phase_df.shape\n",
    "\n",
    "plt.matshow(phase_df)\n",
    "\n",
    "#To-do: reflect radians in bar\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xyPos\n",
    "xyPos is the trajectory traveled by the avatar. Each row is an X-Y data pair in [m] sampled in every ms. It is the biggest file because of the density of points. You can down-sample it to make it more manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyPos = np.loadtxt(dir+'xyPos.csv',delimiter=',')[::25]\n",
    "xyPos[:,1]-= xyPos[:,1].min()\n",
    "xyPos[:,0]-= xyPos[:,0].min()\n",
    "print(xyPos)\n",
    "\n",
    "#Trajectory overlaid with XYspkT\n",
    "plt.plot(xyPos[:,0],xyPos[:,1], color='b')\n",
    "plt.plot(XYspkT[:,0],XYspkT[:,1], '.', color='r', markersize=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MeanPhaseMap DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "phase_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A padded phase map for use in edge-cases for extracting the 5x5 adjacency matrix below\n",
    "padded_phase_map = np.pad(phase_df,pad_width=2,mode='constant',constant_values=np.nan)\n",
    "padded_phase_df = pd.DataFrame(data=padded_phase_map)\n",
    "padded_phase_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjacency Function\n",
    "\n",
    "Adjacent spikes returns the best matching MeanPhaseMap location for the next 6 spikes phases, adjacent matrix returns a 5x5 array to analyze a region of space adjacent to a target location within the MeanPhaseMap, then finds\n",
    "the x and y difference from the center to cell to the cell with the cloest matching value (of phase).\n",
    "\n",
    "example return array:\n",
    "\n",
    "       [ 3.0844,     nan, -1.5684,     nan,     nan],\n",
    "\n",
    "       [ 3.0844,     nan,     nan, -1.6837, -1.5763],\n",
    "       \n",
    "       [    nan,     nan,     nan,     nan, -1.5088],\n",
    "       \n",
    "       [-2.8458,     nan,     nan,     nan, -2.5082],\n",
    "       \n",
    "       [-2.8458,     nan,     nan,     nan,     nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def adjacent_matrix(cell, phase):\n",
    "    \"\"\"Determines change vector from central cell to cell\n",
    "    nearest in value in 5x5 IN FORM **[X,Y]** \"\"\"        \n",
    "    x = int(cell[0])\n",
    "    y = int(cell[1])\n",
    "    y_size = arena_size[0]-1\n",
    "    a = padded_phase_df.iloc[y_size-y:y_size-y+5,x:x+5]\n",
    "\n",
    "    try:\n",
    "        nearest = np.nanargmin(np.abs(a-phase))\n",
    "        loc = [(nearest%5)-2,2-(nearest//5)]\n",
    "\n",
    "        #Rounding down to the nearest bin, adding 0.5 to point to center of bin        \n",
    "        xp = x+loc[0]+0.5\n",
    "        yp = y+loc[1]+0.5    \n",
    "        return[xp - cell[0],yp - cell[1]]\n",
    "\n",
    "    except:\n",
    "        return [0,0]    \n",
    "\n",
    "\n",
    "def adjacent_spikes(spikes, phase):\n",
    "    \"\"\"Get location of spike with most similar phase\"\"\"\n",
    "    y_size = arena_size[0] - 1\n",
    "    phases = []\n",
    "    for i in spikes:\n",
    "        x = int(i[0])\n",
    "        y = int(i[1])\n",
    "        phases.append(phase_df.iloc[y_size - y, x])\n",
    "    phases = np.asarray(phases)\n",
    "    try:\n",
    "        nearest = np.nanargmin(np.abs(phases - phase))\n",
    "    except:\n",
    "        nearest = 0\n",
    "\n",
    "    try:\n",
    "        #Rounding down to the nearest bin, adding 0.5 to point to center of bin\n",
    "        x = int(spikes[nearest][0])+0.5 \n",
    "        y = int(spikes[nearest][1])+0.5\n",
    "        return [x - spikes[0, 0], y - spikes[0, 1]]\n",
    "\n",
    "    except:\n",
    "        return [0.0, 0.0]\n",
    "    \n",
    "    \n",
    "#Tests:\n",
    "#print(adjacent_matrix([3,0.5],-1.5))\n",
    "#adjacent_spikes(combined[10:16,1:3],combined[10,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Position, Time and Phase DataFrame\n",
    "\n",
    "X,Y position, change in distance, time and phase data sorted by trajectory from the Time column in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsorted = np.column_stack((spkT,scaled_XY,scaled_phase))\n",
    "sorted = unsorted[unsorted[:,0].argsort()]\n",
    "\n",
    "#Calculate movement magnitudes\n",
    "xdif = np.append(sorted[1:,1],0)-np.append(sorted[:-1,1],0)\n",
    "ydif = np.append(sorted[1:,2],0)-np.append(sorted[:-1,2],0)\n",
    "\n",
    "#Drop rows with movements below threshold\n",
    "move_thresh = 0.01\n",
    "\n",
    "raw = np.column_stack((sorted,xdif,ydif))\n",
    "print(raw)\n",
    "movement  = raw[np.any(abs(raw[:,4:]) >= move_thresh, axis=1)]\n",
    "\n",
    "#Recalculate movement magnitudes\n",
    "xdif = np.append(movement[1:,1],0)-np.append(movement[:-1,1],0)\n",
    "ydif = np.append(movement[1:,2],0)-np.append(movement[:-1,2],0)\n",
    "next_phase = np.insert(movement[1:,3],-1, 0)\n",
    "\n",
    "combined = np.column_stack((movement[:,:4],next_phase,xdif,ydif))\n",
    "print(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial Analysis\n",
    "if analysis_type == 'spatial':\n",
    "    predicted = [adjacent_matrix([i[1],i[2]],i[4]) for i in combined]\n",
    "    predicted_movement = np.asarray(predicted)\n",
    "\n",
    "# Temporal Analysis    \n",
    "if analysis_type == 'temporal':\n",
    "    predicted = [adjacent_spikes(combined[i:i+6,1:3],combined[i,4]) for i in range(len(combined))]\n",
    "    predicted_movement = np.asarray(predicted)\n",
    "    \n",
    "all=np.column_stack((combined,predicted_movement))\n",
    "df = pd.DataFrame(data=all, columns=['Time','X','Y','Phase','Next Phase','Xdif','Ydif','Xdif Predicted', 'Ydif Predicted'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "ax = plt.subplot()\n",
    "plt.plot(xyPos[:,0]/2, xyPos[:,1]/2, color='b')\n",
    "plt.plot(scaled_XY[:,0], scaled_XY[:,1], '.', color='r', markersize=6)\n",
    "for index, row in df.iterrows():\n",
    "    # if (row['Xdif Predicted']>0) or (row['Ydif Predicted']>0):\n",
    "    plt.arrow(row['X'], row['Y'], row['Xdif Predicted'], row['Ydif Predicted'],\n",
    "                head_width=0.2, color='black')\n",
    "\n",
    "ax.set_xticks(np.arange(scaled_XY[:,0].min()-1,scaled_XY[:,0].max()+2))\n",
    "ax.set_yticks(np.arange(scaled_XY[:,1].min()-1,scaled_XY[:,1].max()+1))\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Angles\n",
    "\n",
    "Calculates the angle between each movements observed and predicted vector angle to store in a list for use\n",
    "in the correlation figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determines the angle between the horizontal axis (+1 x, +0 y) and the current vector, returns [observed,predicted]\n",
    "def abs_vector_angles(arr):\n",
    "    \n",
    "    obs_angles = []\n",
    "    pred_angles = []\n",
    "    \n",
    "    for i in range(len(arr)-1):\n",
    "        p0 = [all[i,1]+1,all[i,2]]\n",
    "        p1 = [all[i,1],all[i,2]]\n",
    "        p2 = [all[i+1,1],all[i+1,2]]\n",
    "        v0 = np.array(p0) - np.array(p1)\n",
    "        v1 = np.array(p2) - np.array(p1)\n",
    "        atan = np.math.atan2(np.linalg.det([v0,v1]),np.dot(v0,v1))\n",
    "        if np.degrees(atan)<0:\n",
    "            obs_angles.append(360+np.degrees(atan))\n",
    "        else:\n",
    "            obs_angles.append(np.degrees(atan))\n",
    "        \n",
    "    for i in range(len(arr)-1):\n",
    "        p0 = [all[i,1]+1,all[i,2]]\n",
    "        p1 = [all[i,1],all[i,2]]\n",
    "        p2 = [all[i,1]+all[i,7],all[i,2]+all[i,8]]\n",
    "        v0 = np.array(p0) - np.array(p1)\n",
    "        v1 = np.array(p2) - np.array(p1)\n",
    "        atan = np.math.atan2(np.linalg.det([v0,v1]),np.dot(v0,v1))\n",
    "        if np.degrees(atan)<0:\n",
    "            pred_angles.append(360+np.degrees(atan))\n",
    "        else:\n",
    "            pred_angles.append(np.degrees(atan))\n",
    "        \n",
    "    return(list(zip(obs_angles,pred_angles)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = np.asarray(abs_vector_angles(all))\n",
    "\n",
    "print('Pearson r correlation (linear): ' + str(pearsonr(angles[:,0],angles[:,1])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='Observed',y='Predicted',data=dt,kind='kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap, xedges, yedges = np.histogram2d(angles[:,0], angles[:,1], bins=60)\n",
    "extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(heatmap.T, extent=extent, origin='lower',cmap='afmhot')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Area\n",
    "\n",
    "Sandbox for developing new features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
